# GANs vs Diffusion Models: Mathematical Frameworks in Action

A comprehensive implementation and comparison of Generative Adversarial Networks (GANs) and Diffusion Models, demonstrating their underlying mathematical frameworks: **Game Theory vs Stochastic Processes**.

![Python](https://img.shields.io/badge/python-v3.8+-blue.svg)
![PyTorch](https://img.shields.io/badge/PyTorch-v1.9+-red.svg)
![License](https://img.shields.io/badge/license-MIT-green.svg)
[![Lightning AI](https://img.shields.io/badge/Lightning%20AI-Studio-purple.svg)](https://lightning.ai)
[![Jupyter](https://img.shields.io/badge/Jupyter-Notebook-orange.svg)](https://jupyter.org/)

## üéØ Overview

This repository demonstrates the fundamental differences between GANs and Diffusion Models through their mathematical foundations:

- **üéÆ GANs**: Implement **Game Theory** (two-player minimax game)
- **üåä Diffusion Models**: Implement **Stochastic Processes** (Markov chain denoising)

Perfect for understanding how different mathematical paradigms lead to different generative modeling approaches.

## üöÄ Quick Start

### üå©Ô∏è Lightning AI Studio (Recommended)
1. Open the notebook in Lightning AI Studio
2. Run cells sequentially  
3. Enjoy interactive comparisons with free GPU!

### üî¨ Google Colab
```bash
!git clone https://github.com/Kalyan1210/gans-vs-diffusion-mathematical-frameworks.git
%cd gans-vs-diffusion-mathematical-frameworks
# Open and run the notebook
```

### üíª Local Setup
```bash
git clone https://github.com/Kalyan1210/gans-vs-diffusion-mathematical-frameworks.git
cd gans-vs-diffusion-mathematical-frameworks
pip install -r requirements.txt
jupyter notebook
```

## üìä Key Results Summary

| Metric | GANs (Game Theory) | Diffusion (Stochastic Process) | Winner |
|--------|--------------------|---------------------------------|---------|
| **‚ö° Generation Speed** | ~0.01s (16 samples) | ~5.4s (16 samples) | üéÆ GANs (540x faster) |
| **üìà Training Stability** | High variance | Low variance | üåä Diffusion (460x more stable) |
| **üéØ Sample Quality** | Good when stable | Consistently excellent | üåä Diffusion |
| **üéõÔ∏è Controllability** | Limited (latent interpolation) | High (partial denoising) | üåä Diffusion |
| **üí° Mathematical Framework** | Nash equilibrium seeking | Score matching | Both (different strengths) |
| **‚ö° Best Use Case** | Real-time applications | High-quality generation | Context dependent |

## üìñ Mathematical Foundations

### üéÆ GANs: Game Theory Framework

GANs implement a **two-player zero-sum game**:

```math
\min_G \max_D V(G,D) = \mathbb{E}_{x \sim p_{data}}[\log D(x)] + \mathbb{E}_{z \sim p_z}[\log(1-D(G(z)))]
```

**üîë Key Concepts:**
- **Players**: Generator (G) vs Discriminator (D)
- **Goal**: Nash Equilibrium where `p_g = p_data`
- **Training**: Alternating gradient updates
- **Challenges**: Mode collapse, training instability, vanishing gradients

**üéØ At Optimal Solution:**
- `D*(x) = 0.5` everywhere (can't distinguish real from fake)
- Generator loss = `-log(4) + 2¬∑JS(p_data||p_g)`

### üåä Diffusion Models: Stochastic Process Framework

Diffusion models learn to **reverse a noise addition process**:

**Forward Process** (adding noise):
```math
q(x_t|x_{t-1}) = \mathcal{N}(x_t; \sqrt{1-\beta_t}x_{t-1}, \beta_t I)
```

**Reverse Process** (denoising):
```math
p_\theta(x_{t-1}|x_t) = \mathcal{N}(x_{t-1}; \mu_\theta(x_t,t), \sigma_t I)
```

**Training Objective**:
```math
\mathcal{L} = \mathbb{E}_{t,x_0,\epsilon}[||\epsilon - \epsilon_\theta(\sqrt{\bar{\alpha}_t}x_0 + \sqrt{1-\bar{\alpha}_t}\epsilon, t)||^2]
```

**üîë Key Concepts:**
- **Markov Chain**: Forward process gradually adds noise
- **Reverse SDE**: Neural network learns to denoise step by step  
- **Score Function**: `‚àá_x log p_t(x)` learned implicitly
- **Ergodicity**: Process reaches stationary distribution `N(0,I)`

## üèóÔ∏è Implementation Highlights

### üéÆ GAN Architecture
```python
class Generator(nn.Module):    # Maps z ‚àà R^100 ‚Üí x ‚àà R^(1√ó28√ó28)
class Discriminator(nn.Module): # Maps x ‚àà R^(1√ó28√ó28) ‚Üí probability ‚àà [0,1]
```

### üåä Diffusion Architecture  
```python
class SimpleDiffusionModel(nn.Module):  # Predicts noise Œµ given (x_t, t)
class DiffusionTrainer:                 # Handles forward/reverse processes
```

### üìà Training Comparison

**üéÆ GAN Training (Game Theory):**
- Two competing networks with opposing objectives
- Loss curves show oscillatory behavior (Nash equilibrium seeking)
- Risk of mode collapse and training instability

**üåä Diffusion Training (Stochastic Process):**
- Single network with unified objective
- Loss curves show monotonic decrease (stable convergence)
- Guaranteed diversity through stochastic process

## üî¨ Experimental Analysis

### ‚ö° Speed Benchmark
- **GAN Generation**: 0.01s for 16 samples ‚ö°
- **Diffusion Generation**: 5.4s for 16 samples üêå  
- **Speed Ratio**: GANs are **540x faster**

### üìä Training Stability  
- **GAN Loss Variance**: High (competing objectives)
- **Diffusion Loss Variance**: Low (single objective)
- **Stability Ratio**: Diffusion is **460x more stable**

### üé® Sample Quality
- **GANs**: Good quality when training is stable
- **Diffusion**: Consistently high quality and diversity
- **Mode Coverage**: Diffusion shows better mode coverage

### üéõÔ∏è Controllability Demo
- **GANs**: Latent space interpolation `z‚ÇÅ ‚Üí z‚ÇÇ`
- **Diffusion**: Partial denoising control (stop at any timestep)

## üéØ Key Insights & Philosophy

### üß† Mathematical Paradigms

| Aspect | Game Theory (GANs) | Stochastic Processes (Diffusion) |
|--------|---------------------|-----------------------------------|
| **Problem Type** | Minimax optimization | Single objective optimization |
| **Solution Concept** | Nash equilibrium | Maximum likelihood estimation |
| **Training Dynamics** | Adversarial (competing) | Cooperative (unified) |
| **Convergence** | Not guaranteed | Theoretically guaranteed |
| **Intuition** | "Competition breeds excellence" | "Learn natural processes" |

### ‚öñÔ∏è Practical Trade-offs

**Choose üéÆ GANs when:**
- ‚ö° Real-time generation needed
- üí∞ Limited computational budget  
- üîÑ Fast iteration cycles required
- üòä Moderate quality acceptable

**Choose üåä Diffusion when:**
- üåü Highest quality needed
- üìà Stable training required
- üéõÔ∏è Controllable generation desired
- üí™ Sufficient compute available

## üìÅ Repository Structure

```
üì¶ gans-vs-diffusion-mathematical-frameworks/
‚îú‚îÄ‚îÄ üìì notebooks/
‚îÇ   ‚îî‚îÄ‚îÄ complete_implementation.ipynb    # Full interactive implementation
‚îú‚îÄ‚îÄ üèóÔ∏è src/                             # Source code modules
‚îÇ   ‚îú‚îÄ‚îÄ models/                         # GAN and Diffusion architectures
‚îÇ   ‚îú‚îÄ‚îÄ utils/                          # Visualization and analysis tools
‚îÇ   ‚îî‚îÄ‚îÄ experiments/                    # Training and comparison scripts
‚îú‚îÄ‚îÄ üé® assets/                          # Generated samples and plots
‚îú‚îÄ‚îÄ üìñ docs/                            # Mathematical documentation
‚îú‚îÄ‚îÄ üìã requirements.txt                 # Python dependencies
‚îú‚îÄ‚îÄ üìÑ README.md                        # This file
‚îú‚îÄ‚îÄ üö´ .gitignore                       # Git ignore rules
‚îî‚îÄ‚îÄ üìú LICENSE                          # MIT License
```

## üõ†Ô∏è Dependencies

```bash
torch>=1.9.0          # Deep learning framework
torchvision>=0.10.0   # Computer vision utilities  
matplotlib>=3.3.0     # Plotting and visualization
numpy>=1.21.0         # Numerical computing
tqdm>=4.62.0          # Progress bars
jupyter>=1.0.0        # Interactive notebooks
scipy>=1.7.0          # Scientific computing
```

## üéì Educational Value

This repository is designed for:

- **üìö Students**: Learning generative models from mathematical foundations
- **üî¨ Researchers**: Understanding trade-offs between different approaches  
- **üë®‚Äçüíª Practitioners**: Choosing the right model for specific applications
- **üß† Theorists**: Seeing how mathematical frameworks translate to code

### üéØ Learning Path
1. **Mathematical Theory**: Understand Game Theory vs Stochastic Processes
2. **Implementation**: See theory translated to working PyTorch code
3. **Experimentation**: Run interactive comparisons and analysis
4. **Applications**: Learn when to use each approach

## ü§ù Contributing

Contributions welcome! Areas for enhancement:

- üî¨ **Model Variants**: StyleGAN, WGAN-GP, DDIM, Latent Diffusion
- üìä **Advanced Metrics**: FID, IS, LPIPS, Precision/Recall
- üé® **Visualizations**: Better training dynamics, loss landscapes
- üìö **Documentation**: More detailed mathematical derivations  
- ‚ö° **Optimizations**: Faster sampling, memory efficiency
- üß™ **Experiments**: Different datasets, ablation studies

### üìù How to Contribute
1. Fork the repository
2. Create feature branch (`git checkout -b feature/amazing-feature`)
3. Commit changes (`git commit -m 'Add amazing feature'`)
4. Push to branch (`git push origin feature/amazing-feature`)
5. Open Pull Request

## üìú License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## üôè Acknowledgments

- **üéì Mathematical Foundation**: 
  - Ian Goodfellow et al. - "Generative Adversarial Networks" (2014)
  - Jonathan Ho et al. - "Denoising Diffusion Probabilistic Models" (2020)
- **üå©Ô∏è Infrastructure**: Lightning AI Studio for providing free GPU access
- **ü§ó Community**: ML Twitter and Reddit for discussions and insights
- **üìö Inspiration**: The need to understand generative models from first principles

## üìû Connect & Follow

- **üë®‚Äçüíª GitHub**: [@Kalyan1210](https://github.com/Kalyan1210)
- **üìß Email**: Open an issue for questions
- **üåü Repository**: Star if you found this helpful!

## üîó Related Resources

- **üìö Papers**: [Original GAN Paper](https://arxiv.org/abs/1406.2661), [DDPM Paper](https://arxiv.org/abs/2006.11239)
- **üéì Courses**: CS231n (Stanford), CS294 (Berkeley)
- **üìñ Books**: Deep Learning (Goodfellow), Pattern Recognition (Bishop)

---

### üåü Star History

```
If you found this repository helpful for understanding generative models, 
please ‚≠ê star it to help others discover these educational resources!
```

---

> *"The best way to understand complex mathematical concepts is through hands-on implementation and direct comparison."* - Philosophy behind this repository

**Built with ‚ù§Ô∏è for the ML community | Powered by Lightning AI ‚ö°**
